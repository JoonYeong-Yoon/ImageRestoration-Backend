from PIL import Image
import os

# ------------------------------------------------------------
# ê¸°ë³¸ í™”ì§ˆ ê°œì„  í•¨ìˆ˜ (ë‹¨ìˆœ ì—…ìŠ¤ì¼€ì¼)
# ------------------------------------------------------------
PROCESSED_FOLDER = os.path.join(os.getcwd(), "backend", "processed")
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

def enhance_image(input_path):
    """í™”ì§ˆ ê°œì„  (ì„ì‹œ: ë‹¨ìˆœ ì—…ìŠ¤ì¼€ì¼)"""
    img = Image.open(input_path)
    enhanced = img.resize((img.width * 2, img.height * 2))
    
    output_path = os.path.join(PROCESSED_FOLDER, "enhanced_" + os.path.basename(input_path))
    enhanced.save(output_path, quality=95)
    return output_path


# ------------------------------------------------------------
# AI ì»¬ëŸ¬í™” ê¸°ëŠ¥ (UNet ê¸°ë°˜)
# ------------------------------------------------------------
import torch
import torchvision.transforms as T
from PIL import Image, ImageEnhance
from torch import nn
import pytorch_lightning as pl
import segmentation_models_pytorch as smp

# âœ… ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
class LitColorization(pl.LightningModule):
    def __init__(self, lr=1e-4):
        super().__init__()
        self.model = smp.Unet(
            encoder_name="resnet34",
            encoder_weights="imagenet",
            in_channels=1,
            classes=3
        )
        self.loss_fn = nn.L1Loss()
        self.lr = lr
        self.activation = nn.Tanh()

    def forward(self, x):
        return self.activation(self.model(x))


# ------------------------------------------------------------
# í™˜ê²½ ì„¤ì •
# ------------------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ê²½ë¡œ ìˆ˜ì • (backend/checkpoints_unet ë°”ë¡œ ì•„ë˜ì— íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •)
MODEL_PATH = os.path.join("checkpoints_unet", "pj2-color.ckpt")

# âœ… ëª¨ë¸ ë¡œë“œ
if os.path.exists(MODEL_PATH):
    print("ğŸ§  AI ëª¨ë¸ ë¡œë“œ ì¤‘...")
    lit_model = LitColorization.load_from_checkpoint(MODEL_PATH)
    lit_model.to(device)
    lit_model.eval()
    print("âœ… AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
else:
    print("âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:", MODEL_PATH)
    lit_model = None


# ------------------------------------------------------------
# Transform ì •ì˜
# ------------------------------------------------------------
transform_gray = T.Compose([
    T.Resize((128, 128)),
    T.ToTensor()
])


# ------------------------------------------------------------
# AI ì»¬ëŸ¬í™” í•¨ìˆ˜
# ------------------------------------------------------------
def colorize_image(file):
    """í‘ë°± ì´ë¯¸ì§€ë¥¼ AIë¡œ ì»¬ëŸ¬ ë³µì›"""
    if lit_model is None:
        raise FileNotFoundError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    img = Image.open(file.stream).convert("L")
    orig_size = img.size
    x = transform_gray(img).unsqueeze(0).to(device)

    with torch.no_grad():
        y_pred = lit_model(x)
        y_pred = (y_pred + 1) / 2
        y_pred = torch.clamp(y_pred, 0, 1)

    # í›„ì²˜ë¦¬ ë° ì €ì¥
    y_pred_pil = T.ToPILImage()(y_pred.squeeze(0).cpu())
    y_pred_pil = y_pred_pil.resize(orig_size, Image.BICUBIC)
    y_pred_pil = ImageEnhance.Sharpness(y_pred_pil).enhance(1.5)

    output_path = os.path.join(PROCESSED_FOLDER, "colorized_result.png")
    y_pred_pil.save(output_path)
    return output_path
